# -*- coding: utf-8 -*-
"""movie.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12bWlnQ7QadDuvyfjO8w8y-TwDW81V-CZ
"""

import pandas as pd
import numpy as np
import json # To parse JSON-like strings
import ast  # For safely evaluating strings containing Python literals

try:
    movies_df = pd.read_csv('/content/tmdb_5000_movies.csv')
    credits_df = pd.read_csv('/content/tmdb_5000_credits.csv')
except FileNotFoundError:
    print("Make sure 'tmdb_5000_movies.csv' and 'tmdb_5000_credits.csv' are in the current directory.")
    exit()

print("--- tmdb_5000_movies.csv (loaded into movies_df) ---")
print(movies_df.head())
print("\n--- tmdb_5000_credits.csv (loaded into credits_df) ---")
print(credits_df.head())

# Rename 'movie_id' in credits_df to 'id' to match the key in movies_df
credits_df.rename(columns={'movie_id': 'id'}, inplace=True)

# Merge the two dataframes on the common 'id' column
df = pd.merge(movies_df, credits_df, on='id')

# Handle the duplicated 'title' column: keep 'title_x' and rename it to 'title'
# The titles should be the same; if not, it indicates a data quality issue.
if 'title_y' in df.columns and 'title_x' in df.columns:
    df.drop('title_y', axis=1, inplace=True)
    df.rename(columns={'title_x': 'title'}, inplace=True)
elif 'title_y' in df.columns and 'title_x' not in df.columns:
    df.rename(columns={'title_y': 'title'}, inplace=True)


print("\n--- Merged DataFrame ---")
print("Shape of Merged DataFrame:", df.shape)
print("\nColumns in Merged DataFrame:", df.columns.tolist())
print("\nMerged DataFrame Info:")
df.info()
print("\nFirst few rows of Merged DataFrame:")
print(df.head())

#Define Target Variables and Select Initial Features

target_cols = ['revenue', 'vote_average']

# Display the selected target columns to verify
print("\n--- Target Columns ---")
print(df[target_cols].head())

# Let's look at a subset of columns we might use or engineer from
print("\n--- Potential Feature Columns (Subset) ---")
potential_feature_preview_cols = [
    'title', 'budget', 'genres', 'keywords', 'popularity',
    'production_companies', 'release_date', 'runtime',
    'vote_count', 'cast', 'crew', 'homepage'
]


print(df[potential_feature_preview_cols + target_cols].head(2))

#Data Cleaning and Basic Preprocessing


# --- Cleaning 'revenue' and 'budget' ---
# Display current shape and some stats before filtering
print(f"Shape before budget/revenue filtering: {df.shape}")
print("Number of movies with budget <= 1000:", (df['budget'] <= 1000).sum())
print("Number of movies with revenue <= 1000:", (df['revenue'] <= 1000).sum())

# Filter out movies with very low budget or revenue
# Similarly for revenue. This helps in getting more meaningful log transformations.
df = df[df['budget'] > 1000]
df = df[df['revenue'] > 1000]

print(f"Shape after filtering low budget/revenue: {df.shape}")

# Log transform 'budget' and 'revenue'
# We use np.log1p which computes log(1 + x) to naturally handle any zeros if they were present
# and to reduce skewness.
df['budget_log'] = np.log1p(df['budget'])
df['revenue_log'] = np.log1p(df['revenue'])

# --- Handling missing 'runtime' ---
print("Missing 'runtime' values before imputation:", df['runtime'].isnull().sum())
median_runtime = df['runtime'].median()
df['runtime'].fillna(median_runtime, inplace=True)
print("Missing 'runtime' values after imputation:", df['runtime'].isnull().sum())


print(df[['budget_log', 'revenue_log', 'vote_average']].describe())

# Display first few rows with new log columns
print("\nDataFrame head with new log-transformed columns:")
print(df[['title', 'budget', 'budget_log', 'revenue', 'revenue_log', 'runtime']].head())

# Step 4: Feature Engineering from JSON-like Columns


# Helper function to parse JSON-like strings safely
def parse_json_col(column_str):
    try:
        # ast.literal_eval is safer for Python literal structures (like list of dicts)
        return ast.literal_eval(column_str)
    except (ValueError, SyntaxError, TypeError): # Added TypeError for potential None values
        return [] # Return empty list if parsing fails or input is not string-like

# --- Engineer 'num_genres' ---
# Apply the parser first, then extract names if needed, or just count
df['genres_list'] = df['genres'].apply(parse_json_col)
df['num_genres'] = df['genres_list'].apply(lambda x: len(x) if isinstance(x, list) else 0)

# --- Engineer 'num_keywords' ---
df['keywords_list'] = df['keywords'].apply(parse_json_col)
df['num_keywords'] = df['keywords_list'].apply(lambda x: len(x) if isinstance(x, list) else 0)

# --- Engineer 'num_cast' and 'num_crew' ---
# The 'cast' and 'crew' columns are also JSON-like strings
df['cast_list'] = df['cast'].apply(parse_json_col)
df['num_cast'] = df['cast_list'].apply(lambda x: len(x) if isinstance(x, list) else 0)

df['crew_list'] = df['crew'].apply(parse_json_col)
df['num_crew'] = df['crew_list'].apply(lambda x: len(x) if isinstance(x, list) else 0)

# --- Engineer 'has_homepage' ---
# Check if 'homepage' column is null or not, convert boolean to int (1 or 0)
df['has_homepage'] = df['homepage'].notna().astype(int)

# --- Engineer 'release_year' and 'release_month' ---
# Ensure 'release_date' is in datetime format
print("Missing 'release_date' values before conversion:", df['release_date'].isnull().sum())
df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce') # 'coerce' will turn unparseable dates into NaT

# Drop rows where date conversion might have failed (resulting in NaT)
# or if release_date was already null.
num_rows_before_date_dropna = df.shape[0]
df.dropna(subset=['release_date'], inplace=True)
num_rows_after_date_dropna = df.shape[0]
if num_rows_before_date_dropna != num_rows_after_date_dropna:
    print(f"Dropped {num_rows_before_date_dropna - num_rows_after_date_dropna} rows due to unparseable/missing release_date.")


df['release_year'] = df['release_date'].dt.year
df['release_month'] = df['release_date'].dt.month
# df['release_dayofweek'] = df['release_date'].dt.dayofweek # Another option for more detail

print("\nEngineered features head (first 5 rows):")
engineered_cols_to_show = ['title', 'num_genres', 'num_keywords', 'num_cast', 'num_crew', 'has_homepage', 'release_year', 'release_month']
print(df[engineered_cols_to_show].head())

print(f"\nShape of DataFrame after feature engineering: {df.shape}")
print("\nQuick check for NaNs in new engineered features:")
print(df[engineered_cols_to_show].isnull().sum())

# Final Feature Selection and Defining X and y

# Define features (X) and targets (y)
# These are the numerical features we prepared or were already numeric and suitable for direct use.
feature_cols = [
    'budget_log',       # Log-transformed budget
    'popularity',
    'runtime',
    'vote_count',
    'num_genres',
    'num_keywords',
    'num_cast',
    'num_crew',
    'has_homepage',
    'release_year',
    'release_month'
]
# Create the feature matrix X
X = df[feature_cols].copy()

# Create the target matrix y
y = df[['revenue_log', 'vote_average']].copy()


print("\nMissing values in selected features (X) before final fill:")
print(X.isnull().sum())

# Fill any remaining NaNs in X with the median of each column.
for col in X.columns:
    if X[col].isnull().any():
        median_val = X[col].median()
        X[col].fillna(median_val, inplace=True)
        print(f"Filled NaNs in '{col}' with median: {median_val}")

print("\nMissing values in X after final fill:")
print(X.isnull().sum())

print("\nMissing values in y:")
print(y.isnull().sum())
# Verify shapes
print("\nShape of X (features):", X.shape)
print("Shape of y (targets):", y.shape)

# Display head of X and y to confirm
print("\nHead of X (features):")
print(X.head())
print("\nHead of y (targets):")
print(y.head())

# Split Data into Training and Testing Sets


from sklearn.model_selection import train_test_split

# Split the data into training (80%) and testing (20%) sets
# random_state ensures reproducibility of the split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\nShapes of training and testing sets:")
print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_test shape: {y_test.shape}")

# Display the first few rows of y_train and y_test to see the split
print("\nHead of y_train:")
print(y_train.head())
print("\nHead of y_test:")
print(y_test.head())

# Step 7: Feature Scaling

print("\n--- Step 7: Feature Scaling ---")

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

# The scaler learns the mean and standard deviation from X_train
X_train_scaled = scaler.fit_transform(X_train)


# We do not fit on X_test to avoid data leakage
X_test_scaled = scaler.transform(X_test)

# X_train_scaled and X_test_scaled are now NumPy arrays.
# For inspection, let's convert them back to DataFrames (optional, but good for viewing)
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)

print("\nFirst 5 rows of scaled X_train (as DataFrame):")
print(X_train_scaled_df.head())

print("\nDescriptive statistics of scaled X_train (should have mean ~0 and std ~1):")
print(X_train_scaled_df.describe())

print("\nFirst 5 rows of scaled X_test (as DataFrame):")
print(X_test_scaled_df.head())

# Note: For model training later, we will use the NumPy arrays: X_train_scaled and X_test_scaled

# Step 8: Model Selection and Training

print("\n--- Step 8: Model Selection and Training ---")

from sklearn.multioutput import MultiOutputRegressor
from sklearn.ensemble import RandomForestRegressor

# Initialize the base regressor.
# RandomForestRegressor is a good general-purpose choice.

base_regressor = RandomForestRegressor(
    n_estimators=100,     # Number of trees in the forest
    random_state=42,      # For reproducibility
    n_jobs=-1,            # Use all available cores
    max_depth=15,         # Maximum depth of the trees (to prevent overfitting)
    min_samples_split=5,  # Minimum number of samples required to split an internal node
    min_samples_leaf=3    # Minimum number of samples required to be at a leaf node
)

# Wrap the base regressor with MultiOutputRegressor
# This will fit one RandomForestRegressor for 'revenue_log' and another for 'vote_average'
model = MultiOutputRegressor(base_regressor)

# --- Train the model ---
# We use X_train_scaled (the NumPy array) and y_train (can be pandas DataFrame)

model.fit(X_train_scaled, y_train)
print("Model training complete.")

# The 'model' object now contains two fitted RandomForestRegressor instances,
# one for each target variable. You can access them via model.estimators_
if hasattr(model, 'estimators_') and len(model.estimators_) > 0:
    print(f"\nNumber of estimators (one per target): {len(model.estimators_)}")
    print(f"Estimator for target 1 ('revenue_log'): {model.estimators_[0]}")
    print(f"Estimator for target 2 ('vote_average'): {model.estimators_[1]}")
else:
    print("\nEstimators not found or model not fitted as expected.")

# Optional: If you wanted to try a simpler model like Linear Regression:
# base_lr = LinearRegression()
# model_lr = MultiOutputRegressor(base_lr)
# print("\nTraining LinearRegression MultiOutputRegressor...")
# model_lr.fit(X_train_scaled, y_train)
# print("Linear Regression training complete.")
# Then you would use model_lr for predictions and evaluation.

# Make Predictions


# Use the trained model to make predictions on the scaled test data (X_test_scaled)
y_pred_scaled = model.predict(X_test_scaled) # Output will be a NumPy array

print(f"\nShape of predictions (y_pred_scaled): {y_pred_scaled.shape}")
print("Predictions are for (revenue_log, vote_average)")

# Display the first 5 predictions
print("\nFirst 5 raw predictions (scaled, for revenue_log and vote_average):")
print(y_pred_scaled[:5])

# For comparison, let's look at the first 5 actual values from y_test
# y_test is a pandas DataFrame, so we use .head() or .iloc[:5]
print("\nFirst 5 actual test values (y_test):")
print(y_test.head().values) # .values to get NumPy array for consistent display with y_pred_scaled

# y_pred_scaled contains:
# Column 0: Predictions for 'revenue_log'
# Column 1: Predictions for 'vote_average'

# Inverse Transform Revenue Predictions


# y_test is a pandas DataFrame. Let's make a copy to modify for actual revenue.
y_test_actual_scale = y_test.copy()

# y_pred_scaled is a NumPy array. Let's make a copy for the actual scale predictions.
y_pred_actual_scale = y_pred_scaled.copy()


# --- Inverse transform the 'revenue_log' column (index 0) in y_test_actual_scale ---
# This converts the actual log revenue back to the original dollar scale.
y_test_actual_scale.iloc[:, 0] = np.expm1(y_test.iloc[:, 0])
# y_test_actual_scale now contains: [actual revenue, actual vote_average]

# --- Inverse transform the 'revenue_log' predictions (column 0) in y_pred_actual_scale ---
# This converts the predicted log revenue back to the original dollar scale.
y_pred_actual_scale[:, 0] = np.expm1(y_pred_scaled[:, 0])
# y_pred_actual_scale now contains: [predicted revenue, predicted vote_average]


# For safety, ensure no negative predictions for revenue after inverse transform,
# as revenue cannot be negative. np.maximum sets any negative values to 0.
y_pred_actual_scale[:, 0] = np.maximum(0, y_pred_actual_scale[:, 0])


print("\nFirst 5 actual test values (revenue in original scale, vote_average):")
# Displaying as NumPy array for consistency with predicted values
print(y_test_actual_scale.head().values)

print("\nFirst 5 predicted values (revenue in original scale, vote_average):")
print(y_pred_actual_scale[:5])

# Sanity check: Compare one original budget with its log and back
if 'budget' in df.columns and 'budget_log' in df.columns:
    original_budget_example = df['budget'].iloc[0]
    log_budget_example = df['budget_log'].iloc[0]
    reverted_budget_example = np.expm1(log_budget_example)
    print(f"\nSanity check for inverse transform (using budget as an example):")
    print(f"Original budget (first movie in df): {original_budget_example:,.0f}")
    print(f"Log1p budget: {log_budget_example:.4f}")
    print(f"Expm1(Log1p budget): {reverted_budget_example:,.0f}")
    # Note: there might be tiny precision differences.

# (Previous code from Step 1 to Step 10 remains the same)

# Step 11: Evaluate the Model and Visualize Results

print("\n--- Step 11: Evaluate the Model and Visualize Results ---")

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
# Ensure plotting libraries are imported if not done at the top
import matplotlib.pyplot as plt
import seaborn as sns

# --- Ensure seaborn style is set if not done globally ---
# sns.set_style("whitegrid") # You can set it here or globally

# Extract actual and predicted values for each target for clarity
# Revenue (original scale)
y_test_revenue_actual = y_test_actual_scale.iloc[:, 0].values # Actual revenue
y_pred_revenue_actual = y_pred_actual_scale[:, 0]            # Predicted revenue

# Vote Average (original scale)
y_test_rating_actual = y_test_actual_scale.iloc[:, 1].values # Actual rating
y_pred_rating_actual = y_pred_actual_scale[:, 1]            # Predicted rating

# --- Evaluation Metrics (as before) ---
print("\n--- Revenue Prediction Evaluation (Original Scale) ---")
rmse_revenue = np.sqrt(mean_squared_error(y_test_revenue_actual, y_pred_revenue_actual))
mae_revenue = mean_absolute_error(y_test_revenue_actual, y_pred_revenue_actual)
r2_revenue = r2_score(y_test_revenue_actual, y_pred_revenue_actual)
print(f"RMSE (Revenue): ${rmse_revenue:,.2f}")
print(f"MAE (Revenue): ${mae_revenue:,.2f}")
print(f"R2 Score (Revenue): {r2_revenue:.4f}")

print("\n--- Vote Average Prediction Evaluation ---")
rmse_rating = np.sqrt(mean_squared_error(y_test_rating_actual, y_pred_rating_actual))
mae_rating = mean_absolute_error(y_test_rating_actual, y_pred_rating_actual)
r2_rating = r2_score(y_test_rating_actual, y_pred_rating_actual)
print(f"RMSE (Rating): {rmse_rating:.4f}")
print(f"MAE (Rating): {mae_rating:.4f}")
print(f"R2 Score (Rating): {r2_rating:.4f}")


# --- VISUALIZATIONS ---

# 1. Distribution of Actual vs. Predicted Values (Revenue)
plt.figure(figsize=(12, 6))
sns.histplot(y_test_revenue_actual, color="blue", label="Actual Revenue", kde=True, stat="density", linewidth=0)
sns.histplot(y_pred_revenue_actual, color="red", label="Predicted Revenue", kde=True, stat="density", linewidth=0)
plt.title('Distribution of Actual vs. Predicted Revenue')
plt.xlabel('Revenue (Original Scale)')
plt.ylabel('Density')
plt.legend()
# Since revenue can have a very wide range and be skewed, a log scale on x-axis might be useful IF needed for visualization
# Be careful with log(0) or negative values if they exist before this point for y_pred_revenue_actual
# plt.xscale('log') # Uncomment if you want to try log scale for x-axis
plt.show()


# 2. Scatter Plot of Actual vs. Predicted Values (Revenue)
plt.figure(figsize=(8, 8))
plt.scatter(y_test_revenue_actual, y_pred_revenue_actual, alpha=0.5)
plt.plot([min(y_test_revenue_actual.min(), y_pred_revenue_actual.min()), max(y_test_revenue_actual.max(), y_pred_revenue_actual.max())],
         [min(y_test_revenue_actual.min(), y_pred_revenue_actual.min()), max(y_test_revenue_actual.max(), y_pred_revenue_actual.max())],
         color='red', linestyle='--', lw=2, label='Perfect Prediction Line (y=x)') # Line y=x
plt.title('Actual vs. Predicted Revenue')
plt.xlabel('Actual Revenue (Original Scale)')
plt.ylabel('Predicted Revenue (Original Scale)')
plt.legend()
plt.grid(True)
# plt.xscale('log') # Optional log scale
# plt.yscale('log') # Optional log scale
plt.show()


# 3. Residual Plot (Revenue)
residuals_revenue = y_test_revenue_actual - y_pred_revenue_actual
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_revenue_actual, residuals_revenue, alpha=0.5)
plt.axhline(y=0, color='red', linestyle='--')
plt.title('Residual Plot for Revenue Prediction')
plt.xlabel('Predicted Revenue (Original Scale)')
plt.ylabel('Residuals (Actual - Predicted)')
plt.grid(True)
plt.show()


# 4. Distribution of Actual vs. Predicted Values (Rating)
plt.figure(figsize=(12, 6))
sns.histplot(y_test_rating_actual, color="blue", label="Actual Rating", kde=True, stat="density", linewidth=0, binwidth=0.25)
sns.histplot(y_pred_rating_actual, color="red", label="Predicted Rating", kde=True, stat="density", linewidth=0, binwidth=0.25)
plt.title('Distribution of Actual vs. Predicted Rating')
plt.xlabel('Vote Average')
plt.ylabel('Density')
plt.legend()
plt.show()


# 5. Scatter Plot of Actual vs. Predicted Values (Rating)
plt.figure(figsize=(8, 8))
plt.scatter(y_test_rating_actual, y_pred_rating_actual, alpha=0.5)
plt.plot([y_test_rating_actual.min(), y_test_rating_actual.max()],
         [y_test_rating_actual.min(), y_test_rating_actual.max()],
         color='red', linestyle='--', lw=2, label='Perfect Prediction Line (y=x)') # Line y=x
plt.title('Actual vs. Predicted Rating')
plt.xlabel('Actual Vote Average')
plt.ylabel('Predicted Vote Average')
plt.xlim(0, 10) # Ratings are typically 0-10
plt.ylim(0, 10)
plt.legend()
plt.grid(True)
plt.show()


# 6. Residual Plot (Rating)
residuals_rating = y_test_rating_actual - y_pred_rating_actual
plt.figure(figsize=(10, 6))
plt.scatter(y_pred_rating_actual, residuals_rating, alpha=0.5)
plt.axhline(y=0, color='red', linestyle='--')
plt.title('Residual Plot for Rating Prediction')
plt.xlabel('Predicted Vote Average')
plt.ylabel('Residuals (Actual - Predicted)')
plt.ylim(-max(abs(residuals_rating.min()), abs(residuals_rating.max())) -1, max(abs(residuals_rating.min()), abs(residuals_rating.max())) +1 ) # Symmetrical y-axis
plt.grid(True)
plt.show()


# --- Feature Importances Plot (as before, but now with plotting) ---
if hasattr(model, 'estimators_') and len(model.estimators_) == 2:
    if isinstance(model.estimators_[0], RandomForestRegressor) and \
       isinstance(model.estimators_[1], RandomForestRegressor):

        print("\n--- Feature Importances (Tabular, as before) ---")
        importances_revenue_vals = model.estimators_[0].feature_importances_
        importances_rating_vals = model.estimators_[1].feature_importances_

        feature_importance_df = pd.DataFrame({
            'Feature': feature_cols, # Defined in Step 5
            'Importance_for_Revenue': importances_revenue_vals,
            'Importance_for_Rating': importances_rating_vals
        })

        print("\nFeature Importances for Revenue Prediction (Sorted):")
        sorted_revenue_importances = feature_importance_df[['Feature', 'Importance_for_Revenue']].sort_values(by='Importance_for_Revenue', ascending=False)
        print(sorted_revenue_importances)

        print("\nFeature Importances for Rating Prediction (Sorted):")
        sorted_rating_importances = feature_importance_df[['Feature', 'Importance_for_Rating']].sort_values(by='Importance_for_Rating', ascending=False)
        print(sorted_rating_importances)

        # 7. Plotting Feature Importances for Revenue
        plt.figure(figsize=(10, 7))
        sns.barplot(x='Importance_for_Revenue', y='Feature', data=sorted_revenue_importances, palette="viridis")
        plt.title('Feature Importances for Revenue Prediction')
        plt.xlabel('Importance Score')
        plt.ylabel('Feature')
        plt.tight_layout()
        plt.show()

        # 8. Plotting Feature Importances for Rating
        plt.figure(figsize=(10, 7))
        sns.barplot(x='Importance_for_Rating', y='Feature', data=sorted_rating_importances, palette="mako")
        plt.title('Feature Importances for Rating Prediction')
        plt.xlabel('Importance Score')
        plt.ylabel('Feature')
        plt.tight_layout()
        plt.show()
else:
    print("\nFeature importances cannot be displayed/plotted for the current model configuration.")

print("\n--- End of Project ---")